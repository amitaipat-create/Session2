{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitaipat-create/Session2/blob/main/Another_copy_of_Mission_3_Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice 2: LangChain Agents with Tools"
      ],
      "metadata": {
        "id": "SAIlpSrce6qx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maLdsciTaTlV"
      },
      "outputs": [],
      "source": [
        "%pip install langchain==0.3.27 langchain-openai==0.3.29 langchain-community==0.3.27 langchain-core pydantic==2.11.10 python-dotenv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqoNWQVca5j6",
        "outputId": "383f4f6c-4e51-4252-f732-e16237d8be41"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
      ],
      "metadata": {
        "id": "7PVROQ2wbCFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 1: create_tool_calling_agent() Setup\n",
        "# Learning: Create an agent that can call tools automatically\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 1: create_tool_calling_agent() Setup\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Create a simple tool\n",
        "@tool\n",
        "def get_skill_level(skill: str) -> str:\n",
        "    \"\"\"Get experience level for a skill\"\"\"\n",
        "    levels = {\n",
        "        \"Python\": \"5 years\",\n",
        "        \"FastAPI\": \"3 years\",\n",
        "        \"PostgreSQL\": \"2 years\"\n",
        "    }\n",
        "    return levels.get(skill, \"No experience\")\n",
        "\n",
        "# Create prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Use tools to answer questions.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "# Create agent\n",
        "tools = [get_skill_level]\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"What's the experience level for Python?\"})\n",
        "print(f\"Agent response: {result['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UTLHb-MbCDc",
        "outputId": "cd044a2c-f56a-4a03-b242-3c43b747a34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 1: create_tool_calling_agent() Setup\n",
            "------------------------------------------------------------\n",
            "Agent response: The experience level for Python is 5 years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 1: Create a Tool for Skill Matching\n",
        "# Task: Create a tool that checks if a skill exists in a list\n",
        "# Instructions:\n",
        "#   1. Create a tool called 'check_skill' that takes two parameters:\n",
        "#      - skill: str (the skill to check)\n",
        "#      - skill_list: str (comma-separated skills like \"Python, FastAPI, Docker\")\n",
        "#   2. Return \"Found\" if skill is in the list, \"Not found\" otherwise\n",
        "#   3. Add it to the tools and test with the agent\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yBKV8kB0bI_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 2: Custom Tool Creation with @tool Decorator\n",
        "# Learning: Create custom tools for specific tasks\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 2: Custom Tool Creation\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "@tool\n",
        "def extract_skills(text: str) -> str:\n",
        "    \"\"\"Extract technical skills from text\"\"\"\n",
        "    skills = []\n",
        "    skill_keywords = [\"Python\", \"FastAPI\", \"PostgreSQL\", \"Docker\", \"AWS\"]\n",
        "    for keyword in skill_keywords:\n",
        "        if keyword.lower() in text.lower():\n",
        "            skills.append(keyword)\n",
        "    return \", \".join(skills) if skills else \"No skills found\"\n",
        "\n",
        "@tool\n",
        "def calculate_match_score(required_skills: str, candidate_skills: str) -> str:\n",
        "    \"\"\"Calculate match score between required and candidate skills\"\"\"\n",
        "    required = set(required_skills.split(\", \"))\n",
        "    candidate = set(candidate_skills.split(\", \"))\n",
        "    matched = required.intersection(candidate)\n",
        "    score = (len(matched) / len(required)) * 100 if required else 0\n",
        "    return f\"Match score: {score:.1f}% ({len(matched)}/{len(required)} skills matched)\"\n",
        "\n",
        "# Test tools\n",
        "tools_list = [extract_skills, calculate_match_score]\n",
        "test_agent = create_tool_calling_agent(llm, tools_list, prompt)\n",
        "test_executor = AgentExecutor(agent=test_agent, tools=tools_list, verbose=False)\n",
        "\n",
        "result = test_executor.invoke({\n",
        "    \"input\": \"Extract skills from 'Python developer with FastAPI and Docker experience'\"\n",
        "})\n",
        "print(f\"Tool result: {result['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8j2hVeDbfp8",
        "outputId": "0621bb84-107f-4303-e125-d7c7d15a53aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 2: Custom Tool Creation\n",
            "------------------------------------------------------------\n",
            "Tool result: The extracted skills are:\n",
            "- Python\n",
            "- FastAPI\n",
            "- Docker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 2: Try It Out - Create Tools for Job Matching (DO IT LATER)\n",
        "# Task: Create tools that work together for job matching\n",
        "# Instructions:\n",
        "#   1. Create a tool 'get_years_experience' that extracts years from text\n",
        "#      Example: \"5 years Python\" -> returns \"5\"\n",
        "#   2. Create a tool 'check_experience_requirement' that compares years\n",
        "#      Takes: candidate_years (int), required_years (int)\n",
        "#      Returns: \"Meets requirement\" or \"Below requirement\"\n",
        "#   3. Create an agent with both tools and test with:\n",
        "#      \"Candidate has 3 years Python experience. Job requires 5 years. Check if they meet requirement\"\n",
        "# ============================================================================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w-tbE5zPdi70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 3: Agent Memory (ConversationBufferMemory)\n",
        "# Learning: Give agents memory to remember previous conversations\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 3: Agent Memory\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Create memory\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# Update prompt to include memory\n",
        "prompt_with_memory = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Remember previous conversation.\"),\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "# Create agent with memory\n",
        "agent_with_memory = create_tool_calling_agent(llm, tools_list, prompt_with_memory)\n",
        "memory_executor = AgentExecutor(\n",
        "    agent=agent_with_memory,\n",
        "    tools=tools_list,\n",
        "    memory=memory,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# First question\n",
        "result1 = memory_executor.invoke({\"input\": \"Extract skills from 'Python developer'\"})\n",
        "print(f\"Q1: {result1['output']}\")\n",
        "\n",
        "# Follow-up (agent remembers context)\n",
        "result2 = memory_executor.invoke({\"input\": \"What was the previous skill?\"})\n",
        "print(f\"Q2: {result2['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrKsLP45bsXL",
        "outputId": "921fa004-890e-4d0d-c139-17dd25d56bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 3: Agent Memory\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-353751966.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: The extracted skill from \"Python developer\" is: **Python**.\n",
            "Q2: The previous skill extracted was **Python**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 3: Try It Out - Memory in Action (EASY)\n",
        "# Task: Create a simple 2-turn conversation where agent remembers\n",
        "# Instructions:\n",
        "#   1. Copy the memory setup from Concept 3 above (lines 136-156)\n",
        "#   2. Create 2 simple exchanges:\n",
        "#      - Turn 1: Ask \"What is your name?\"\n",
        "#      - Turn 2: Ask \"What did I say my name was?\" (agent should remember!)\n",
        "#   3. That's it! Just test that memory works\n",
        "# ============================================================================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9bliQD-weIj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 4: Structured Outputs (Pydantic Models)\n",
        "# Learning: Get structured data from agents using Pydantic\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 4: Structured Outputs\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "class SkillAnalysis(BaseModel):\n",
        "    skills: List[str] = Field(description=\"List of technical skills found\")\n",
        "    count: int = Field(description=\"Number of skills\")\n",
        "    primary_skill: str = Field(description=\"Most important skill\")\n",
        "\n",
        "# Use structured output\n",
        "structured_llm = llm.with_structured_output(SkillAnalysis)\n",
        "\n",
        "result = structured_llm.invoke(\n",
        "    \"Analyze this: 'Senior Python developer with FastAPI and PostgreSQL experience'\"\n",
        ")\n",
        "print(f\"Structured output: {result}\")\n",
        "print(f\"Skills: {result.skills}\")\n",
        "print(f\"Primary: {result.primary_skill}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-dLW6h3bzXj",
        "outputId": "80315a28-9d1e-4cfd-9a95-151824347a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 4: Structured Outputs\n",
            "------------------------------------------------------------\n",
            "Structured output: skills=['Python', 'FastAPI', 'PostgreSQL'] count=3 primary_skill='Python'\n",
            "Skills: ['Python', 'FastAPI', 'PostgreSQL']\n",
            "Primary: Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 4: Try It Out - Create MatchResult Model (EASY)\n",
        "# Task: Create a Pydantic model for match results and use structured output\n",
        "# Instructions:\n",
        "#   1. Create a MatchResult class with:\n",
        "#      - match_score: float (0-100)\n",
        "#      - matched_skills: List[str]\n",
        "#      - missing_skills: List[str]\n",
        "#   2. Use it with structured_llm to analyze a job match\n",
        "#   3. Test with: \"Job requires: Python, FastAPI, PostgreSQL. Candidate has: Python, FastAPI.\"\n",
        "# ============================================================================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQTNUGMfeQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 5: Tool Integration and Execution\n",
        "# Learning: Agents automatically decide when and how to use tools\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 5: Tool Integration\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "@tool\n",
        "def get_job_requirements(job_title: str) -> str:\n",
        "    \"\"\"Get requirements for a job title\"\"\"\n",
        "    requirements = {\n",
        "        \"Software Engineer\": \"Python, FastAPI, PostgreSQL, Docker\",\n",
        "        \"Data Scientist\": \"Python, Machine Learning, SQL, Statistics\"\n",
        "    }\n",
        "    return requirements.get(job_title, \"Requirements not found\")\n",
        "\n",
        "all_tools = [get_job_requirements, extract_skills, calculate_match_score]\n",
        "multi_tool_agent = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "multi_executor = AgentExecutor(agent=multi_tool_agent, tools=all_tools, verbose=True)\n",
        "\n",
        "result = multi_executor.invoke({\n",
        "    \"input\": \"Get requirements for Software Engineer, then extract skills from 'Python developer with FastAPI', then calculate match score\"\n",
        "})\n",
        "print(f\"Multi-tool result: {result['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS_4u4Jqb3s7",
        "outputId": "2065d4f7-cde5-48e1-e1b1-9df134341157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 5: Tool Integration\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_job_requirements` with `{'job_title': 'Software Engineer'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mPython, FastAPI, PostgreSQL, Docker\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `extract_skills` with `{'text': 'Python developer with FastAPI'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPython, FastAPI\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `calculate_match_score` with `{'required_skills': 'Python, FastAPI, PostgreSQL, Docker', 'candidate_skills': 'Python, FastAPI'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mMatch score: 50.0% (2/4 skills matched)\u001b[0m\u001b[32;1m\u001b[1;3mThe requirements for a Software Engineer include the following skills: **Python, FastAPI, PostgreSQL, Docker**.\n",
            "\n",
            "The skills extracted from the text \"Python developer with FastAPI\" are: **Python, FastAPI**.\n",
            "\n",
            "The match score between the required skills and the candidate skills is **50.0%** (2 out of 4 skills matched).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Multi-tool result: The requirements for a Software Engineer include the following skills: **Python, FastAPI, PostgreSQL, Docker**.\n",
            "\n",
            "The skills extracted from the text \"Python developer with FastAPI\" are: **Python, FastAPI**.\n",
            "\n",
            "The match score between the required skills and the candidate skills is **50.0%** (2 out of 4 skills matched).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 5: Try It Out - Chain Multiple Tools (DO IT LATER)\n",
        "# Task: Create an agent that uses multiple tools in sequence\n",
        "# Instructions:\n",
        "#   1. Create a tool 'get_skill_description' that returns description for a skill\n",
        "#      Example: \"Python\" -> \"High-level programming language for general-purpose programming\"\n",
        "#   2. Combine it with existing tools (extract_skills, calculate_match_score)\n",
        "#   3. Ask agent to: extract skills, get descriptions, then calculate match\n",
        "#   4. Agent should use tools in logical sequence automatically\n",
        "# ============================================================================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-QFGDZ9hedI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 6: Agent Conversation Flow\n",
        "# Learning: Maintain context across multiple exchanges (essential for interview agent)\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 6: Agent Conversation Flow\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Reset memory for clean example\n",
        "interview_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "interview_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an interview agent. Ask questions and remember responses.\"),\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "interview_agent = create_tool_calling_agent(llm, [], interview_prompt)  # No tools for simple interview\n",
        "interview_executor = AgentExecutor(\n",
        "    agent=interview_agent,\n",
        "    tools=[],\n",
        "    memory=interview_memory,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Multi-turn conversation\n",
        "print(\"Interview conversation:\")\n",
        "response1 = interview_executor.invoke({\"input\": \"Ask me about my Python experience\"})\n",
        "print(f\"Agent: {response1['output']}\")\n",
        "\n",
        "response2 = interview_executor.invoke({\"input\": \"I have 5 years of Python experience\"})\n",
        "print(f\"Agent: {response2['output']}\")\n",
        "\n",
        "response3 = interview_executor.invoke({\"input\": \"What did I say about my experience?\"})\n",
        "print(f\"Agent: {response3['output']}\")  # Agent remembers!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU-iEGj5b_jt",
        "outputId": "22959b78-93e7-4493-8d47-a884b4419aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 6: Agent Conversation Flow\n",
            "------------------------------------------------------------\n",
            "Interview conversation:\n",
            "Agent: Sure! How long have you been working with Python, and what types of projects or applications have you developed using it?\n",
            "Agent: That's great! In those 5 years, what types of projects or applications have you worked on? Are there any specific areas of Python that you specialize in, such as data analysis, web development, automation, or something else?\n",
            "Agent: You mentioned that you have 5 years of Python experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXERCISE 6: Try It Out - Memory + Tools Together (CAN DO IT LATER)\n",
        "# Task: Create an agent with memory that uses tools across multiple turns\n",
        "# Instructions:\n",
        "#   1. Create agent with memory + tools (extract_skills, calculate_match_score)\n",
        "#   2. First turn: Extract skills from candidate description\n",
        "#   3. Second turn: Calculate match score (agent should remember extracted skills)\n",
        "#   4. Third turn: Ask agent to summarize the match (should remember everything)\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "eKwQQjePcO3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}