{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitaipat-create/Session2/blob/main/Copy_of_Mission_3_Practice_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain==0.3.27 langchain-openai==0.3.29 langchain-community==0.3.27 sentence-transformers qdrant-client langchain-qdrant python-dotenv --quiet"
      ],
      "metadata": {
        "id": "bLhmFgu1K-Aq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API Key (for chat models, not embeddings - we use local)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "ii47cgMIK4cc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PRACTICE 1: EMBEDDINGS & VECTOR STORES\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjliHoThX1MK",
        "outputId": "f62bc181-bfe6-42db-b275-b5f8f190b22d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PRACTICE 1: EMBEDDINGS & VECTOR STORES\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 1: Generate embeddings for multiple texts\n",
        "# Task: Create a list of 3 different job titles/descriptions\n",
        "# Use embeddings.embed_documents() to generate embeddings for all texts\n",
        "# Print the number of embeddings generated\n",
        "\n"
      ],
      "metadata": {
        "id": "vDUUo2mNY-R8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 2: Qdrant Vector Store Setup\n",
        "# Learning: Initialize and connect to Qdrant vector database\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 2: Qdrant Vector Store Setup\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Create in-memory Qdrant client (for practice - use cloud in production)\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "# Create collection with 768 dimensions (matching our embedding model)\n",
        "collection_name = \"resumes\"\n",
        "try:\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=VectorParams(\n",
        "            size=768,  # all-mpnet-base-v2 dimension\n",
        "            distance=Distance.COSINE\n",
        "        )\n",
        "    )\n",
        "    print(f\"Created collection: {collection_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Collection may already exist: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpJFbUOVZBOZ",
        "outputId": "10bac504-386e-47d7-d944-2498111204de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 2: Qdrant Vector Store Setup\n",
            "------------------------------------------------------------\n",
            "Created collection: resumes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 3: Document Chunking and Embedding Storage\n",
        "# Learning: Chunk documents and store with embeddings in Qdrant\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 3: Document Chunking and Embedding Storage\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Sample resume text\n",
        "resume_text = \"\"\"\n",
        "John Doe - Software Engineer\n",
        "5 years experience in Python, FastAPI, PostgreSQL\n",
        "Worked on microservices architecture\n",
        "Expert in REST APIs and database design\n",
        "\"\"\"\n",
        "\n",
        "# Chunk the resume (500 tokens, 50 overlap)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = text_splitter.split_text(resume_text)\n",
        "\n",
        "print(f\"Original text length: {len(resume_text)}\")\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "print(f\"First chunk: {chunks[0][:100]}...\")\n",
        "\n",
        "# Store chunks in Qdrant with embeddings\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=collection_name,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "# Add documents with metadata (must be Document objects, not dicts)\n",
        "documents = [\n",
        "    Document(page_content=chunk, metadata={\"candidate_id\": \"john_doe\", \"chunk_id\": i})\n",
        "    for i, chunk in enumerate(chunks)\n",
        "]\n",
        "\n",
        "vector_store.add_documents(documents)\n",
        "print(f\"Stored {len(documents)} chunks in Qdrant\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUGHsxgDZJYB",
        "outputId": "8a287601-598a-4f5f-b551-55285876d2dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 3: Document Chunking and Embedding Storage\n",
            "------------------------------------------------------------\n",
            "Original text length: 157\n",
            "Number of chunks: 1\n",
            "First chunk: John Doe - Software Engineer\n",
            "5 years experience in Python, FastAPI, PostgreSQL\n",
            "Worked on microservic...\n",
            "Stored 1 chunks in Qdrant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 2: Chunk and store a different resume\n",
        "# Task: Create a new resume text for a different candidate (e.g., \"Jane Smith - Data Scientist\")\n",
        "# Use text_splitter to chunk it, add metadata with candidate_id=\"jane_smith\"\n",
        "# Store the chunks in vector_store using add_documents()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B_f_B98eZSZo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 4: Semantic Search Implementation\n",
        "# Learning: Search for similar documents using semantic similarity\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nCONCEPT 4: Semantic Search Implementation\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Search query\n",
        "query = \"Python developer with API experience\"\n",
        "print(f\"Search query: {query}\")\n",
        "\n",
        "# Perform semantic search\n",
        "results = vector_store.similarity_search(query, k=2)\n",
        "\n",
        "print(f\"\\nFound {len(results)} similar documents:\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. {doc.page_content[:100]}...\")\n",
        "    print(f\"   Metadata: {doc.metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSN3H35qZWu7",
        "outputId": "2a22f016-6bea-4de3-f279-e896bb909cef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 4: Semantic Search Implementation\n",
            "------------------------------------------------------------\n",
            "Search query: Python developer with API experience\n",
            "\n",
            "Found 1 similar documents:\n",
            "\n",
            "1. John Doe - Software Engineer\n",
            "5 years experience in Python, FastAPI, PostgreSQL\n",
            "Worked on microservic...\n",
            "   Metadata: {'candidate_id': 'john_doe', 'chunk_id': 0, '_id': '934b4a772d6c4a5597e6f28f862fcf86', '_collection_name': 'resumes'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 5: Similarity Matching and Scoring\n",
        "# Learning: Get similarity scores with search results\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 5: Similarity Matching and Scoring\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Search with scores\n",
        "results_with_scores = vector_store.similarity_search_with_score(query, k=2)\n",
        "\n",
        "print(f\"Results with similarity scores:\")\n",
        "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
        "    print(f\"\\n{i}. Score: {score:.4f}\")\n",
        "    print(f\"   Content: {doc.page_content[:80]}...\")\n",
        "    # Lower score = more similar (cosine distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRtetjS7Zch2",
        "outputId": "72c368f1-bd5c-4145-cfcd-062994885c27"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 5: Similarity Matching and Scoring\n",
            "------------------------------------------------------------\n",
            "Results with similarity scores:\n",
            "\n",
            "1. Score: 0.5519\n",
            "   Content: John Doe - Software Engineer\n",
            "5 years experience in Python, FastAPI, PostgreSQL\n",
            "W...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 3: Search for \"machine learning\" and compare scores\n",
        "# Task: Use similarity_search_with_score() to search for \"machine learning\"\n",
        "# Print each result with its similarity score\n",
        "# Compare the scores - lower score means more similar\n",
        "\n"
      ],
      "metadata": {
        "id": "uKp-_qkIZnez"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aO2yVSuABpO",
        "outputId": "5f1f45e3-4bf1-4cac-cfa2-3b47c5a56d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CONCEPT 6: Metadata Filtering in Vector Search\n",
            "------------------------------------------------------------\n",
            "Filtered results (only john_doe): 1\n",
            "  - John Doe - Software Engineer\n",
            "5 years experience in Python, F... (ID: john_doe)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONCEPT 6: Metadata Filtering in Vector Search\n",
        "# Learning: Filter search results by metadata (e.g., candidate_id)\n",
        "# ============================================================================\n",
        "print(\"\\nCONCEPT 6: Metadata Filtering in Vector Search\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "# Search with metadata filter\n",
        "# Note: For simplicity, we'll search without filter and filter results manually\n",
        "# In production, use proper Qdrant Filter objects for better performance\n",
        "all_results = vector_store.similarity_search(query=\"Python developer\", k=5)\n",
        "filtered_results = [doc for doc in all_results if doc.metadata.get(\"candidate_id\") == \"john_doe\"]\n",
        "\n",
        "print(f\"Filtered results (only john_doe): {len(filtered_results)}\")\n",
        "for doc in filtered_results:\n",
        "    print(f\"  - {doc.page_content[:60]}... (ID: {doc.metadata['candidate_id']})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 4: Search for \"data science\" filtered to jane_smith\n",
        "# Task: Use similarity_search() with filter parameter\n",
        "# Search for \"data science\" but only return results where candidate_id=\"jane_smith\"\n",
        "# Print the number of filtered results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bUB0IgpBZvMO"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}